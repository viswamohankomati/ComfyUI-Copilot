[
    {
        "name": "添加LoRA",
        "description": "在现有工作流中添加LoRA节点",
        "content": "在现有工作流中添加LoRA节点，确保与现有模型和提示词节点正确连接\n    在checkpoint节点后添加LoRA节点。\n    {\n      \"1\": {\n         \"inputs\": {\n            \"lora_name\": \"DOG.safetensors\",\n            \"strength_model\": 1,\n            \"strength_clip\": 1,\n            \"model\": [\n            \"2\",\n            0\n            ],\n            \"clip\": [\n            \"2\",\n            1\n            ]\n         },\n         \"class_type\": \"LoraLoader\",\n         \"_meta\": {\n            \"title\": \"Load LoRA\"\n         }\n      }"
    },
    {
        "name": "后处理增强",
        "description": "后处理增强，例如在Preview Image或Save Image节点后添加高清放大功能（如Real-ESRGAN、ESRGAN等）; 或者添加图像缩放节点",
        "content": "- 在Preview Image或Save Image节点后添加高清放大功能（如Real-ESRGAN、ESRGAN等）\n       - 添加图像缩放节点\n       {\n  \"1\": {\n    \"inputs\": {\n      \"width\": 512,\n      \"height\": 512,\n      \"interpolation\": \"nearest\",\n      \"method\": \"stretch\",\n      \"condition\": \"always\",\n      \"multiple_of\": 0\n    },\n    \"class_type\": \"ImageResize+\",\n    \"_meta\": {\n      \"title\": \"🔧 Image Resize\"\n    }\n  }\n}\n       - 添加图像尺寸调整节点\n       {\n  \"2\": {\n    \"inputs\": {\n      \"aspect_ratio\": \"original\",\n      \"proportional_width\": 2,\n      \"proportional_height\": 1,\n      \"fit\": \"letterbox\",\n      \"method\": \"lanczos\",\n      \"round_to_multiple\": \"8\",\n      \"scale_to_longest_side\": false,\n      \"longest_side\": 1024\n    },\n    \"class_type\": \"LayerUtility: ImageScaleByAspectRatio\",\n    \"_meta\": {\n      \"title\": \"LayerUtility: ImageScaleByAspectRatio\"\n    }\n  }\n}\n   -添加图像放大节点\n  \"11\": {\n    \"inputs\": {\n      \"width\": 512,\n      \"height\": 512,\n      \"upscale_method\": \"nearest-exact\",\n      \"keep_proportion\": false,\n      \"divisible_by\": 2,\n      \"crop\": \"disabled\",\n      \"image\": [\n        \"12\",\n        0\n      ]\n    },\n    \"class_type\": \"ImageResizeKJ\",\n    \"_meta\": {\n      \"title\": \"Resize Image\"\n    }\n  },\n   -添加VAEdecode节点\n  \"12\": {\n    \"inputs\": {},\n    \"class_type\": \"VAEDecode\",\n    \"_meta\": {\n      \"title\": \"VAE Decode\"\n    }\n  }\n}"
    },
    {
        "name": "提示词优化",
        "description": "修改现有提示词节点的内容(提示词应该在(CLIP Text Encode Prompt或Text _O节点内编辑); 添加单独的提示词输入节点",
        "content": "{\n  \"12\": {\n    \"inputs\": {\n      \"text\": [\n        \"13\",\n        0\n      ]\n    },\n    \"class_type\": \"CLIPTextEncode\",\n    \"_meta\": {\n      \"title\": \"CLIP Text Encode (Prompt)\"\n    }\n  },\n  \"13\": {\n    \"inputs\": {\n      \"delimiter\": \", \",\n      \"clean_whitespace\": \"true\",\n      \"text_a\": [\n        \"15\",\n        0\n      ],\n      \"text_b\": [\n        \"16\",\n        0\n      ]\n    },\n    \"class_type\": \"Text Concatenate\",\n    \"_meta\": {\n      \"title\": \"Text Concatenate\"\n    }\n  },\n  \"15\": {\n    \"inputs\": {\n      \"text\": \"\"\n    },\n    \"class_type\": \"Text _O\",\n    \"_meta\": {\n      \"title\": \"Text _O\"\n    }\n  },\n  \"16\": {\n    \"inputs\": {\n      \"text\": \"\"\n    },\n    \"class_type\": \"Text _O\",\n    \"_meta\": {\n      \"title\": \"Text _O\"\n    }\n  }\n}"
    },
    {
        "name": "图像反推",
        "description": "理解图片信息并用文字表达出来",
        "content": "添加图像反推节点（如CLIP Interrogator）\n{\n  \"11\": {\n    \"inputs\": {\n      \"prompt_mode\": \"fast\",\n      \"image_analysis\": \"off\"\n    },\n    \"class_type\": \"ClipInterrogator\",\n    \"_meta\": {\n      \"title\": \"Clip Interrogator ♾️Mixlab\"\n    }\n  }\n}\n       - 添加更复杂或者更好用的图像反推节点(加载图片使用florence2进行反推)\n       {\n  \"6\": {\n    \"inputs\": {\n      \"image\": \"06.JPG\"\n    },\n    \"class_type\": \"LoadImage\",\n    \"_meta\": {\n      \"title\": \"$image.image!:The image to analyze, must be a url\"\n    }\n  },\n  \"10\": {\n    \"inputs\": {\n      \"model\": \"microsoft/Florence-2-large\",\n      \"precision\": \"fp16\",\n      \"attention\": \"sdpa\"\n    },\n    \"class_type\": \"DownloadAndLoadFlorence2Model\",\n    \"_meta\": {\n      \"title\": \"DownloadAndLoadFlorence2Model\"\n    }\n  },\n  \"11\": {\n    \"inputs\": {\n      \"text_input\": \"\",\n      \"task\": \"more_detailed_caption\",\n      \"fill_mask\": true,\n      \"keep_model_loaded\": false,\n      \"max_new_tokens\": 1024,\n      \"num_beams\": 3,\n      \"do_sample\": true,\n      \"output_mask_select\": \"\",\n      \"seed\": 1098631327477633,\n      \"image\": [\n        \"6\",\n        0\n      ],\n      \"florence2_model\": [\n        \"10\",\n        0\n      ]\n    },\n    \"class_type\": \"Florence2Run\",\n    \"_meta\": {\n      \"title\": \"Florence2Run\"\n    }\n  },\n  \"18\": {\n    \"inputs\": {\n      \"anything\": [\n        \"11\",\n        2\n      ]\n    },\n    \"class_type\": \"easy showAnything\",\n    \"_meta\": {\n      \"title\": \"Show Any\"\n    }\n  },\n  \"20\": {\n    \"inputs\": {\n      \"value\": \"Generate high-quality text descriptions from images using local Florence model.\\n    \\n    Main use cases:\\n    1. **Reverse image prompt generation**:\\n       - When users upload an image and want to get prompts for AI art generation\\n       - Analyzes visual elements, style, composition, etc. to generate prompts for Stable Diffusion, DALL-E, and other models\\n       - In this case, return the tool's raw output directly to users without any modification or summary\\n       - Users can directly use these prompts for image generation\\n    2. **Image content understanding**:\\n       - When users ask about specific content, objects, scenes, people, etc. in the image\\n       - Need to understand the semantic content of the image and answer users' specific questions\\n       - In this case, combine tool output with conversation context to give users contextually appropriate natural responses\\n       - Don't return raw output directly, but provide targeted replies based on understanding results\"\n    },\n    \"class_type\": \"PrimitiveStringMultiline\",\n    \"_meta\": {\n      \"title\": \"MCP\"\n    }\n  }\n}"
    },
    {
        "name": "sdxl特征保持",
        "description": "当用户在使用sdxl工作流并需提及特征保持时优先推荐该类工作流，旨在保持图像的特征提取、保持主体结构不变、保持主体形状、控制人物角色姿态、保持场景的深度和空间结构、基于线稿或者草图生成图像等场景下，可以用添加ControlNet节点来实现",
        "content": "**ControlNet集成**：(preprocessor可选canny、depth等参数,模型样式选择，Controlnet开始、结束权重)\n       {\n  \"22\": {\n    \"inputs\": {\n      \"strength\": 1,\n      \"start_percent\": 0,\n      \"end_percent\": 1,\n      \"control_net\": [\n        \"23\",\n        0\n      ],\n      \"image\": [\n        \"24\",\n        0\n      ]\n    },\n    \"class_type\": \"ControlNetApplyAdvanced\",\n    \"_meta\": {\n      \"title\": \"Apply ControlNet\"\n    }\n  },\n  \"23\": {\n    \"inputs\": {\n      \"control_net_name\": \"ControlNet-Standard-Lineart-for-SDXL.safetensors\"\n    },\n    \"class_type\": \"ControlNetLoader\",\n    \"_meta\": {\n      \"title\": \"Load ControlNet Model\"\n    }\n  },\n  \"24\": {\n    \"inputs\": {\n      \"preprocessor\": \"none\",\n      \"resolution\": 512\n    },\n    \"class_type\": \"AIO_Preprocessor\",\n    \"_meta\": {\n      \"title\": \"AIO Aux Preprocessor\"\n    }\n  }\n}"
    },
    {
        "name": "flux风格特征迁移",
        "description": "当用户在使用flux的工作流并提及风格特征迁移时优先推荐该节点，该类节用途主要应用于flux工作流的图片风格特征迁移和提取，风格转换，两张图片参考迁移，重绘遮罩区域或重绘背景，使用时请先分析是否为flux工作流",
        "content": "{\n  \"1\": {\n    \"inputs\": {\n      \"downsampling_factor\": 3,\n      \"downsampling_function\": \"area\",\n      \"mode\": \"center crop (square)\",\n      \"weight\": 1,\n      \"autocrop_margin\": 0.1,\n      \"style_model\": [\n        \"2\",\n        0\n      ],\n      \"clip_vision\": [\n        \"3\",\n        0\n      ]\n    },\n    \"class_type\": \"ReduxAdvanced\",\n    \"_meta\": {\n      \"title\": \"ReduxAdvanced\"\n    }\n  },\n  \"2\": {\n    \"inputs\": {\n      \"style_model_name\": \"flux1-redux-dev.safetensors\"\n    },\n    \"class_type\": \"StyleModelLoader\",\n    \"_meta\": {\n      \"title\": \"Load Style Model\"\n    }\n  },\n  \"3\": {\n    \"inputs\": {\n      \"clip_name\": \"sigclip_vision_patch14_384.safetensors\"\n    },\n    \"class_type\": \"CLIPVisionLoader\",\n    \"_meta\": {\n      \"title\": \"Load CLIP Vision\"\n    }\n  }\n}"
    },
    {
        "name": "sdxl特征迁移",
        "description": "当用户在使用sdxl工作流并提及特征迁移时优先推荐该类工作流，旨在保持图像的特征提取、颜色提取,保持主体不变重绘背景或改变遮罩区域内容，可以用添加IPAdapter Advanced节点来实现",
        "content": "**IPAdapter集成**：(weight type可选linear、ease in-out等参数,weight可选0.1-1开始、结束权重可选0.1-1) {\n  \"1\": {\n    \"inputs\": {\n      \"weight\": 1,\n      \"weight_type\": \"linear\",\n      \"combine_embeds\": \"concat\",\n      \"start_at\": 0,\n      \"end_at\": 1,\n      \"embeds_scaling\": \"V only\",\n      \"ipadapter\": [\n        \"2\",\n        0\n      ],\n      \"clip_vision\": [\n        \"3\",\n        0\n      ]\n    },\n    \"class_type\": \"IPAdapterAdvanced\",\n    \"_meta\": {\n      \"title\": \"IPAdapter Advanced\"\n    }\n  },\n  \"2\": {\n    \"inputs\": {\n      \"ipadapter_file\": \"ip-adapter_sdxl_vit-h.safetensors\"\n    },\n    \"class_type\": \"IPAdapterModelLoader\",\n    \"_meta\": {\n      \"title\": \"IPAdapter Model Loader\"\n    }\n  },\n  \"3\": {\n    \"inputs\": {\n      \"clip_name\": \"CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors\"\n    },\n    \"class_type\": \"CLIPVisionLoader\",\n    \"_meta\": {\n      \"title\": \"Load CLIP Vision\"\n    }\n  }\n}"
    },
    {
        "name": "扩图",
        "description": "给我一个扩图链路(包括图像加载和图像输出)",
        "content": "{\n  \"1\": {\n    \"inputs\": {\n      \"image\": \"01.JPG\"\n    },\n    \"class_type\": \"LoadImage\",\n    \"_meta\": {\n      \"title\": \"$image.image!:The image to analyze, must be a url\"\n    }\n  },\n  \"2\": {\n    \"inputs\": {\n      \"model\": \"runwayml/stable-diffusion-xl-base-1.0\",\n      \"precision\": \"fp16\",\n      \"attention\": \"sdpa\"\n    },\n    \"class_type\": \"DownloadAndLoadModel\",\n    \"_meta\": {\n      \"title\": \"DownloadAndLoadModel\"\n    }\n  },\n  \"3\": {\n    \"inputs\": {\n      \"prompt\": \"A beautiful girl with long hair and a white dress\",\n      \"image\": [\n        \"1\",\n        0\n      ],\n      \"model\": [\n        \"2\",\n        0\n      ]\n    },\n    \"class_type\": \"StableDiffusionXLRun\",\n    \"_meta\": {\n      \"title\": \"StableDiffusionXLRun\"\n    }\n  },\n  \"4\": {\n    \"inputs\": {\n      \"image\": [\n        \"3\",\n        0\n      ]\n    },\n    \"class_type\": \"easy showImage\",\n    \"_meta\": {\n      \"title\": \"Show Image\"\n    }\n  }\n}"
    },
    {
        "name": "智能抠图",
        "description": "添加背景移除节点（如SAM、U²-Net等）",
        "content": "- 添加背景移除或抠图节点\n       {\n  \"7\": {\n    \"inputs\": {\n      \"rem_mode\": \"RMBG-1.4\",\n      \"image_output\": \"Preview\",\n      \"save_prefix\": \"ComfyUI\",\n      \"torchscript_jit\": false,\n      \"add_background\": \"none\",\n      \"refine_foreground\": false\n    },\n    \"class_type\": \"easy imageRemBg\",\n    \"_meta\": {\n      \"title\": \"Image Remove Bg\"\n    }\n  }\n}\n       - 添加SAM抠图节点\n       {\n  \"8\": {\n    \"inputs\": {\n      \"prompt\": \"\",\n      \"threshold\": 0.3,\n      \"sam_model\": [\n        \"9\",\n        0\n      ],\n      \"grounding_dino_model\": [\n        \"10\",\n        0\n      ]\n    },\n    \"class_type\": \"GroundingDinoSAMSegment (segment anything)\",\n    \"_meta\": {\n      \"title\": \"GroundingDinoSAMSegment (segment anything)\"\n    }\n  },\n  \"9\": {\n    \"inputs\": {\n      \"model_name\": \"sam_vit_h (2.56GB)\"\n    },\n    \"class_type\": \"SAMModelLoader (segment anything)\",\n    \"_meta\": {\n      \"title\": \"SAMModelLoader (segment anything)\"\n    }\n  },\n  \"10\": {\n    \"inputs\": {\n      \"model_name\": \"GroundingDINO_SwinT_OGC (694MB)\"\n    },\n    \"class_type\": \"GroundingDinoModelLoader (segment anything)\",\n    \"_meta\": {\n      \"title\": \"GroundingDinoModelLoader (segment anything)\"\n    }\n  }\n}"
    },
    {
        "name": "kontext图像编辑",
        "description": "添加kontext系列节点(这个系列是文生图和图生图场景应用的模型和节点,适合用针对图像的融合，二次编辑,包括但不限于去水印、擦除物体、多元素融合、图片元素提取等)",
        "content": "{\n  \"6\": {\n    \"inputs\": {\n      \"text\": \"\",\n      \"clip\": [\n        \"38\",\n        0\n      ]\n    },\n    \"class_type\": \"CLIPTextEncode\",\n    \"_meta\": {\n      \"title\": \"CLIP Text Encode (Prompt)\"\n    }\n  },\n  \"8\": {\n    \"inputs\": {\n      \"samples\": [\n        \"31\",\n        0\n      ],\n      \"vae\": [\n        \"39\",\n        0\n      ]\n    },\n    \"class_type\": \"VAEDecode\",\n    \"_meta\": {\n      \"title\": \"VAE Decode\"\n    }\n  },\n  \"31\": {\n    \"inputs\": {\n      \"seed\": 584043043142251,\n      \"steps\": 30,\n      \"cfg\": 1.5,\n      \"sampler_name\": \"euler\",\n      \"scheduler\": \"simple\",\n      \"denoise\": 1,\n      \"model\": [\n        \"37\",\n        0\n      ],\n      \"positive\": [\n        \"35\",\n        0\n      ],\n      \"negative\": [\n        \"135\",\n        0\n      ],\n      \"latent_image\": [\n        \"124\",\n        0\n      ]\n    },\n    \"class_type\": \"KSampler\",\n    \"_meta\": {\n      \"title\": \"KSampler\"\n    }\n  },\n  \"35\": {\n    \"inputs\": {\n      \"guidance\": 2.5,\n      \"conditioning\": [\n        \"177\",\n        0\n      ]\n    },\n    \"class_type\": \"FluxGuidance\",\n    \"_meta\": {\n      \"title\": \"FluxGuidance\"\n    }\n  },\n  \"37\": {\n    \"inputs\": {\n      \"unet_name\": \"flux1-dev-kontext_fp8_scaled.safetensors\",\n      \"weight_dtype\": \"fp8_e4m3fn\"\n    },\n    \"class_type\": \"UNETLoader\",\n    \"_meta\": {\n      \"title\": \"Load Diffusion Model\"\n    }\n  },\n  \"38\": {\n    \"inputs\": {\n      \"clip_name1\": \"clip_l.safetensors\",\n      \"clip_name2\": \"t5xxl_fp16.safetensors\",\n      \"type\": \"flux\",\n      \"device\": \"default\"\n    },\n    \"class_type\": \"DualCLIPLoader\",\n    \"_meta\": {\n      \"title\": \"DualCLIPLoader\"\n    }\n  },\n  \"39\": {\n    \"inputs\": {\n      \"vae_name\": \"ae.safetensors\"\n    },\n    \"class_type\": \"VAELoader\",\n    \"_meta\": {\n      \"title\": \"Load VAE\"\n    }\n  },\n  \"42\": {\n    \"inputs\": {\n      \"image\": [\n        \"194\",\n        0\n      ]\n    },\n    \"class_type\": \"FluxKontextImageScale\",\n    \"_meta\": {\n      \"title\": \"FluxKontextImageScale\"\n    }\n  },\n  \"124\": {\n    \"inputs\": {\n      \"pixels\": [\n        \"42\",\n        0\n      ],\n      \"vae\": [\n        \"39\",\n        0\n      ]\n    },\n    \"class_type\": \"VAEEncode\",\n    \"_meta\": {\n      \"title\": \"VAE Encode\"\n    }\n  },\n  \"135\": {\n    \"inputs\": {\n      \"conditioning\": [\n        \"6\",\n        0\n      ]\n    },\n    \"class_type\": \"ConditioningZeroOut\",\n    \"_meta\": {\n      \"title\": \"ConditioningZeroOut\"\n    }\n  },\n  \"177\": {\n    \"inputs\": {\n      \"conditioning\": [\n        \"6\",\n        0\n      ],\n      \"latent\": [\n        \"124\",\n        0\n      ]\n    },\n    \"class_type\": \"ReferenceLatent\",\n    \"_meta\": {\n      \"title\": \"ReferenceLatent\"\n    }\n  },\n  \"193\": {\n    \"inputs\": {\n      \"filename_prefix\": \"ComfyUI\",\n      \"images\": [\n        \"8\",\n        0\n      ]\n    },\n    \"class_type\": \"SaveImage\",\n    \"_meta\": {\n      \"title\": \"Save Image\"\n    }\n  },\n  \"194\": {\n    \"inputs\": {\n      \"image\": \"021175655C8A2A86C831C96855F3EF23.png\"\n    },\n    \"class_type\": \"LoadImage\",\n    \"_meta\": {\n      \"title\": \"Load Image\"\n    }\n  }\n}"
    },
    {
        "name": "qwen image图像生成",
        "description": "基于Qwen-Image多模态大模型的文生图解决方案，支持中英文提示词，擅长生成包含复杂文本的图像内容。适用于海报设计、广告创意等需要稳定生成文字内容的场景",
        "content": "添加qwen image模型,使用qwen image 文生图，创作一张海报，适合生成稳定的文字(当用户提到需要使用qwen image系列时给它提供如下的节点和模型选择：load Difussion Model节点对应qwen_image名字的模型，Load CLIP对应的clip_name:qwen_2.5_vl,type：qwen_image,Load VAE节点对应的模型为:qwen_image_vae.safetensors)"
    },
    {
        "name": "wan2.2图生视频",
        "description": "wan2.2是图像生成视频的模型，主要用来帮助用户根据图片加提示词来生成视频。",
        "content": "{\n  \"11\": {\n    \"inputs\": {\n      \"model_name\": \"umt5-xxl-enc-bf16.safetensors\",\n      \"precision\": \"bf16\",\n      \"load_device\": \"offload_device\",\n      \"quantization\": \"disabled\"\n    },\n    \"class_type\": \"LoadWanVideoT5TextEncoder\",\n    \"_meta\": {\n      \"title\": \"WanVideo T5 Text Encoder Loader\"\n    }\n  },\n  \"16\": {\n    \"inputs\": {\n      \"positive_prompt\": \"猫咪的头部猛的向前一探\",\n      \"negative_prompt\": \"色调艳丽，过曝，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多，倒着走\",\n      \"force_offload\": true,\n      \"use_disk_cache\": false,\n      \"device\": \"gpu\",\n      \"t5\": [\n        \"11\",\n        0\n      ]\n    },\n    \"class_type\": \"WanVideoTextEncode\",\n    \"_meta\": {\n      \"title\": \"WanVideo TextEncode\"\n    }\n  },\n  \"28\": {\n    \"inputs\": {\n      \"enable_vae_tiling\": false,\n      \"tile_x\": 272,\n      \"tile_y\": 272,\n      \"tile_stride_x\": 144,\n      \"tile_stride_y\": 128,\n      \"normalization\": \"default\",\n      \"vae\": [\n        \"38\",\n        0\n      ],\n      \"samples\": [\n        \"90\",\n        0\n      ]\n    },\n    \"class_type\": \"WanVideoDecode\",\n    \"_meta\": {\n      \"title\": \"WanVideo Decode\"\n    }\n  },\n  \"38\": {\n    \"inputs\": {\n      \"model_name\": \"Wan2_1_VAE_bf16.safetensors\",\n      \"precision\": \"bf16\"\n    },\n    \"class_type\": \"WanVideoVAELoader\",\n    \"_meta\": {\n      \"title\": \"WanVideo VAE Loader\"\n    }\n  },\n  \"39\": {\n    \"inputs\": {\n      \"blocks_to_swap\": 20,\n      \"offload_img_emb\": false,\n      \"offload_txt_emb\": false,\n      \"use_non_blocking\": false,\n      \"vace_blocks_to_swap\": 1\n    },\n    \"class_type\": \"WanVideoBlockSwap\",\n    \"_meta\": {\n      \"title\": \"WanVideo Block Swap\"\n    }\n  },\n  \"56\": {\n    \"inputs\": {\n      \"lora\": \"Wan21_I2V_14B_lightx2v_cfg_step_distill_lora_rank64.safetensors\",\n      \"strength\": 3,\n      \"low_mem_load\": true,\n      \"merge_loras\": false\n    },\n    \"class_type\": \"WanVideoLoraSelect\",\n    \"_meta\": {\n      \"title\": \"WanVideo Lora Select\"\n    }\n  },\n  \"89\": {\n    \"inputs\": {\n      \"width\": 832,\n      \"height\": 480,\n      \"num_frames\": 81,\n      \"noise_aug_strength\": 0,\n      \"start_latent_strength\": 1,\n      \"end_latent_strength\": 1,\n      \"force_offload\": true,\n      \"fun_or_fl2v_model\": false,\n      \"tiled_vae\": false,\n      \"vae\": [\n        \"38\",\n        0\n      ]\n    },\n    \"class_type\": \"WanVideoImageToVideoEncode\",\n    \"_meta\": {\n      \"title\": \"WanVideo ImageToVideo Encode\"\n    }\n  },\n  \"90\": {\n    \"inputs\": {\n      \"steps\": 8,\n      \"cfg\": 1,\n      \"shift\": 8,\n      \"seed\": 652251640766870,\n      \"force_offload\": true,\n      \"scheduler\": \"unipc\",\n      \"riflex_freq_index\": 0,\n      \"denoise_strength\": 1,\n      \"batched_cfg\": false,\n      \"rope_function\": \"comfy\",\n      \"start_step\": 4,\n      \"end_step\": -1,\n      \"image_embeds\": [\n        \"89\",\n        0\n      ],\n      \"text_embeds\": [\n        \"16\",\n        0\n      ]\n    },\n    \"class_type\": \"WanVideoSampler\",\n    \"_meta\": {\n      \"title\": \"WanVideo Sampler\"\n    }\n  },\n  \"150\": {\n    \"inputs\": {\n      \"lora\": [\n        \"56\",\n        0\n      ]\n    },\n    \"class_type\": \"WanVideoSetLoRAs\",\n    \"_meta\": {\n      \"title\": \"WanVideo Set LoRAs\"\n    }\n  }\n}"
    },
    {
        "name": "qwen_image_edit",
        "description": "qwen_image_edit是qwen_image文生图所延展的图片编辑功能的工作流，其功能类似于flux_kontext的能力,主要应用在对于图片的修改。当用户提及到需要对生成图进行二次编辑，修改图片内容、改变图片中的某些元素、根据图片图片中的某些特征进行二次延展时，优先推荐该类工作流。",
        "content": "特别注意qwen_image_deit有特定的一套\"difussion model\"和\"clip\"、\"vae\"模型，分别是\"difussion model:qwen_image_edit.safetensor\"、\"clip:qwen_2.5vl_7b_fp8_scaled.safetensors\"和\"qwen_image type\",\"vae:qwen_image_vae\"。另外，对于qwen_image_edit的文本输入节点需要使用专属的\"textencoedqwenimageedit\"除此之外该类工作流不与画布上其他的model共用需单独添加上述专属节点和model。 {\n  \"37\": {\n    \"inputs\": {\n      \"unet_name\": \"qwen_image_edit_fp8_e4m3fn.safetensors\",\n      \"weight_dtype\": \"default\"\n    },\n    \"class_type\": \"UNETLoader\",\n    \"_meta\": {\n      \"title\": \"Load Diffusion Model\"\n    }\n  },\n  \"38\": {\n    \"inputs\": {\n      \"clip_name\": \"qwen_2.5_vl_7b_fp8_scaled.safetensors\",\n      \"type\": \"qwen_image\",\n      \"device\": \"default\"\n    },\n    \"class_type\": \"CLIPLoader\",\n    \"_meta\": {\n      \"title\": \"Load CLIP\"\n    }\n  },\n  \"39\": {\n    \"inputs\": {\n      \"vae_name\": \"qwen_image_vae.safetensors\"\n    },\n    \"class_type\": \"VAELoader\",\n    \"_meta\": {\n      \"title\": \"Load VAE\"\n    }\n  },\n  \"66\": {\n    \"inputs\": {\n      \"shift\": 3,\n      \"model\": [\n        \"37\",\n        0\n      ]\n    },\n    \"class_type\": \"ModelSamplingAuraFlow\",\n    \"_meta\": {\n      \"title\": \"ModelSamplingAuraFlow\"\n    }\n  },\n  \"75\": {\n    \"inputs\": {\n      \"strength\": 1,\n      \"model\": [\n        \"66\",\n        0\n      ]\n    },\n    \"class_type\": \"CFGNorm\",\n    \"_meta\": {\n      \"title\": \"CFGNorm\"\n    }\n  },\n  \"76\": {\n    \"inputs\": {\n      \"prompt\": \"\",\n      \"clip\": [\n        \"38\",\n        0\n      ],\n      \"vae\": [\n        \"39\",\n        0\n      ],\n      \"image\": [\n        \"93\",\n        0\n      ]\n    },\n    \"class_type\": \"TextEncodeQwenImageEdit\",\n    \"_meta\": {\n      \"title\": \"TextEncodeQwenImageEdit\"\n    }\n  },\n  \"77\": {\n    \"inputs\": {\n      \"prompt\": \"\",\n      \"clip\": [\n        \"38\",\n        0\n      ],\n      \"vae\": [\n        \"39\",\n        0\n      ],\n      \"image\": [\n        \"93\",\n        0\n      ]\n    },\n    \"class_type\": \"TextEncodeQwenImageEdit\",\n    \"_meta\": {\n      \"title\": \"TextEncodeQwenImageEdit\"\n    }\n  },\n  \"88\": {\n    \"inputs\": {\n      \"pixels\": [\n        \"93\",\n        0\n      ],\n      \"vae\": [\n        \"39\",\n        0\n      ]\n    },\n    \"class_type\": \"VAEEncode\",\n    \"_meta\": {\n      \"title\": \"VAE Encode\"\n    }\n  },\n  \"93\": {\n    \"inputs\": {\n      \"upscale_method\": \"lanczos\",\n      \"megapixels\": 1\n    },\n    \"class_type\": \"ImageScaleToTotalPixels\",\n    \"_meta\": {\n      \"title\": \"Scale Image to Total Pixels\"\n    }\n  }\n}"
    }
]